{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObJ-wgPO93nJ"
      },
      "source": [
        "#@title Author: Michael Evans { display-mode: \"form\" }\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h8d4KK-95sl"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook demonstrates a workflow for generating a map of predicted solar array footprints using a trained [fully convolutional neural network (FCNN)](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf), specifically [U-net](https://arxiv.org/abs/1505.04597) in Tensorflow. In this example, we create and export images that contain the same variables as used to train our model - the 3 visible, infrared, and 2 near-infrared bands of Sentinel-2 imagery from Google Earth Engine. We load the trained model structure and [weights](https://osf.io/eg35t/) and then run overlapping subsets of these images through the trained model to generate a 2-band output raster containing per-pixel probabilities and classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foiZFwAhu5FY"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "from os.path import join\n",
        "import ee\n",
        "\n",
        "from tensorflow.python.keras import models\n",
        "from sys import path\n",
        "import numpy as np\n",
        "import rasterio as rio\n",
        "import json\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import colors\n",
        "from tensorflow.python.keras import models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-8MlFrmuycO"
      },
      "source": [
        "# Authenticate and initiatlize GEE Account\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6tuEC1yvEdP"
      },
      "source": [
        "## Clone repo containing preprocessing and prediction functions\n",
        "!git clone https://github.com/mjevans26/Satellite_ComputerVision.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2UDJlJyvKT9"
      },
      "source": [
        "# Load the necessary modules from repo\n",
        "path.append('./Satellite_ComputerVision')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm8LpdnwvHEm"
      },
      "source": [
        "from utils.model_tools import get_model, make_confusion_matrix, weighted_bce\n",
        "from utils.prediction_tools import doExport, makePredDataset, make_array_predictions, get_img_bounds, write_tfrecord_prediction, write_geotiff_prediction\n",
        "from utils.clouds import basicQA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmWIhMaxxS0o"
      },
      "source": [
        "# Define a method for displaying Earth Engine image tiles to a folium map.\n",
        "def add_ee_layer(self, ee_image_object, vis_params, name):\n",
        "  map_id_dict = ee.Image(ee_image_object).getMapId(vis_params)\n",
        "  folium.raster_layers.TileLayer(\n",
        "    tiles = map_id_dict['tile_fetcher'].url_format,\n",
        "    attr = \"Map Data Â© Google Earth Engine\",\n",
        "    name = name,\n",
        "    overlay = True,\n",
        "    control = True\n",
        "  ).add_to(self)\n",
        "\n",
        "# Add EE drawing method to folium.\n",
        "folium.Map.add_ee_layer = add_ee_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fPiFxk_xWn7"
      },
      "source": [
        "# Specify names locations for outputs in Cloud Storage. \n",
        "BUCKET = '{YOUR_GCS BUCKET HERE}'\n",
        "BUCKET_PATH = join('gs://', BUCKET)\n",
        "FOLDER = '{YOUR PROJECT FOLDER HERE}'\n",
        "PRED_BASE = '{YOUR PROJECT SUBDIRECTORY FOR PREDICTION FILES HERE}'\n",
        "MODEL_PATH = '{PATH TO MODEL .h5 File}'\n",
        "MODEL_WEIGHTS = '{PATH TO MODEL WEIGHTS .hdf5 file}'\n",
        "\n",
        "# Specify inputs (Sentinel bands) to the model and the response variable.\n",
        "opticalBands = ['B2', 'B3', 'B4']\n",
        "thermalBands = ['B8', 'B11', 'B12']\n",
        "\n",
        "BANDS = opticalBands + thermalBands"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT7d4APrvjJG"
      },
      "source": [
        "## Test images\n",
        "We first need to create and export some images in GEE on which we can run predictions. This notebook uses a few test aois, but you can incorporate your own study areas in GEE or existing Sentinel-2 imagery"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSaS7FOgvyco"
      },
      "source": [
        "# create several small aois to test predictions. These are all in NC\n",
        "aois = dict({\n",
        "    'Test1': ee.Geometry.Polygon(\n",
        "        [[[-78.19610376358034, 35.086989862385884],\n",
        "          [-78.19610376358034, 34.735631502732396],\n",
        "          [-77.67974634170534, 34.735631502732396],\n",
        "          [-77.67974634170534, 35.086989862385884]]], None, False),\n",
        "    'Test2': ee.Geometry.Polygon(\n",
        "        [[[-81.59087915420534, 35.84308746418702],\n",
        "          [-81.59087915420534, 35.47711130797561],\n",
        "          [-81.03057641983034, 35.47711130797561],\n",
        "          [-81.03057641983034, 35.84308746418702]]], None, False),\n",
        "    'Test3': ee.Geometry.Polygon(\n",
        "        [[[-78.74447677513596, 36.4941960586897],\n",
        "          [-78.74447677513596, 36.17115435938789],\n",
        "          [-78.21713302513596, 36.17115435938789],\n",
        "          [-78.21713302513596, 36.4941960586897]]], None, False),\n",
        "    'Test4': ee.Geometry.Polygon(\n",
        "        [[[-76.62411544701096, 36.33505523381603],\n",
        "          [-76.62411544701096, 36.03800955668766],\n",
        "          [-76.16818282982346, 36.03800955668766],\n",
        "          [-76.16818282982346, 36.33505523381603]]], None, False)\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA36Bcwfv1U_"
      },
      "source": [
        "# Choose the GEE folder in which to ingest prediction image:\n",
        "aoi = 'Test4'\n",
        "\n",
        "# prediction path\n",
        "test_path = join(FOLDER, PRED_BASE, aoi)\n",
        "\n",
        "# Base file name to use for TFRecord files and assets. The name structure includes:\n",
        "test_image_base = 'unet256_' + aoi\n",
        "\n",
        "# Half this will extend on the sides of each patch.\n",
        "kernel_buffer = [128, 128]\n",
        "\n",
        "test_region = aois[aoi]\n",
        "\n",
        "# find the center of our aoi for map visualization\n",
        "center = test_region.centroid(5).coordinates().getInfo()\n",
        "center.reverse()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7xAe359wG8n"
      },
      "source": [
        "# Create a test image\n",
        "S2 = ee.ImageCollection(\"COPERNICUS/S2\")\n",
        "\n",
        "## Change dates here\n",
        "######\n",
        "begin = '2020-05-01'\n",
        "end = '2020-08-30'\n",
        "######\n",
        "\n",
        "# The image input collection is cloud-masked.\n",
        "filtered = S2.filterDate(begin, end)\\\n",
        ".filterBounds(test_region)\\\n",
        ".filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\\\n",
        ".map(basicQA)\n",
        "\n",
        "# Create a simple median composite to visualize\n",
        "## Change .clip to change test area \n",
        "test = filtered.median().select(BANDS).clip(test_region)\n",
        "\n",
        "# Use folium to visualize the imagery.\n",
        "#mapid = image.getMapId({'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3})\n",
        "rgbParams = {'bands': ['B4', 'B3', 'B2'],\n",
        "             'min': 0,\n",
        "             'max': 3000}\n",
        "\n",
        "nirParams = {'bands': ['B8', 'B11', 'B12'],\n",
        "             'min': 0,\n",
        "             'max': 3000}\n",
        "\n",
        "\n",
        "## Change coordinates to center map based on aoi used \n",
        "map = folium.Map(location=center)\n",
        "map.add_ee_layer(test, rgbParams, 'Color')\n",
        "map.add_ee_layer(test, nirParams, 'Thermal')\n",
        "\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBW7l5xQxG1Y"
      },
      "source": [
        "# Run the export.\n",
        "## takes some time (~10 min) --> check GEE tasks to see when completed \n",
        "doExport(test, features = BANDS, pred_path = test_path, pred_base = test_image_base, scale = 10, bucket = BUCKET, region = test_region)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfg9rxv4xHuS"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYgzH4DpAw2o"
      },
      "source": [
        "First we load the model structure and weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd7ysDkezBR1"
      },
      "source": [
        "def get_weighted_bce(y_true,y_pred):\n",
        "  return weighted_bce(y_true, y_pred, 1)\n",
        "m = models.load_model(f'{MODEL_PATH}', custom_objects = {'get_weighted_bce': get_weighted_bce})\n",
        "# m = get_model(depth = DEPTH, optim = OPTIMIZER, loss = get_weighted_bce, mets = METRICS, bias = None)\n",
        "m.load_weights(f'{MODEL_WEIGHTS}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sePpmbMPA0xG"
      },
      "source": [
        "Then generate a file list of our previously exported image data on which we want to make predictions. NOTE: This example reads from Google Cloud Storage, but any means of generating a list of filenames is sufficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtgnbS3Q1xmy"
      },
      "source": [
        "predFiles = !gsutil ls {join(BUCKET_PATH, test_path, test_image_base + '*.tfrecord.gz')}\n",
        "jsonFile = !gsutil ls {join(BUCKET_PATH, test_path, test_image_base + '*.json')}\n",
        "jsonFile = jsonFile[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgyohfwV1rqT"
      },
      "source": [
        "# load our predictions data into a Dataset and inspect the first one\n",
        "predData = makePredDataset(predFiles, BANDS, one_hot = None)\n",
        "iterator = iter(predData)\n",
        "print(iterator.next())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG9KksCBBG9F"
      },
      "source": [
        "Generate and plot the output predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebY2MYsv18HO"
      },
      "source": [
        "# generate prediction rasters\n",
        "preds = make_array_predictions(imageDataset = predData, model = m, jsonFile = jsonFile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F1da8OA2CEM"
      },
      "source": [
        "# We can quickly visualize the predictions to see if they look sensible\n",
        "figure = plt.figure(figsize = (12,12))\n",
        "\n",
        "prob = preds[:, :, 0]\n",
        "cls = out_image[:, :, 0]\n",
        "\n",
        "plt.imshow(prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBG2Ndga2MJr"
      },
      "source": [
        "# overlay the predicted outputs on the original satellite data map\n",
        "heatmap = folium.raster_layers.ImageOverlay(\n",
        "    image=prob,\n",
        "    bounds= get_img_bounds(prob, jsonFile),\n",
        "    colormap=lambda x: (0.5, 0, 0.5, 1) if x >= 0.9 else (0, 0, 0, 0),\n",
        ")\n",
        "map.add_child(heatmap)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ouKDMpcBJbL"
      },
      "source": [
        "Export and save predictions (optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rYA_HkF2kMV"
      },
      "source": [
        "# optionally, write predictions to either tfrecord files (best for re-ingesting into GEE)...\n",
        "write_tfrecord_predictions(predData, m, test_path, test_image_base)\n",
        "#...or a geotiff\n",
        "write_geotiff_predictions(image, jsonFile, '{OUTFILE}'):"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}